### A method and deployment scheme for semantic-based image search and retrieval

#### Background
- The retrieval of images (including text and image search) is a prevalent application scenario across various industries. For instance, in the context of an online shopping platform, users can perform similar product searches based on map-based queries. Similarly, in the domain of cloud photo albums, relevant image materials can be located by conducting searches using specific images.

#### The scheme's introduction

- CLIP Model
  - CLIP (Contrastive Language–Image Pre-training) builds on a large body of work on zero-shot transfer, natural language supervision, and multimodal learning,allowing AI to understand the relationship between images and their corresponding descriptions.
    The article provides further insights into the CLIP model.[CLIP: Connecting text and images](https://openai.com/research/clip)
    
    ![截屏2024-04-07 11 06 52](https://github.com/mingyu110/Best-Practice/assets/48540798/e58851d6-cca4-44d3-a46e-c6e24b54243a)

- Amazon OpenSearch k-NN
  - The Amazon OpenSearch platform provides support for k-NN search, enabling the identification of the "nearest neighbor" between points in a vector space through either Euclidean or cosine distance metrics.

#### The diagram of solution architecture
  ![CLIP进行图搜](https://github.com/mingyu110/Best-Practice/assets/48540798/a6c7029a-6504-4b25-92b8-c63acd1d6bd3)

- The operational procedure of the solution：
  - 1）：Develop an Amazon SageMaker model for conducting batch and real-time inference by utilizing a pre-trained CLIP model.
  - 2)：The Amazon SageMaker platform can be utilized for conducting batch transform jobs to generate image embeddings or text embeddings describing images.
  - 3)：Leverage Amazon SageMaker real-time inference (or serverless inference) to perform real-time encoding of images and text, resulting in the generation of image Embeddings or text Embeddings for image descriptions.
  - 4): The raw images and Embedding files generated by the Amazon SageMaker batch conversion job should be stored in Amazon S3, which serves as the primary storage service.
  - 5): The Amazon OpenSearch service enables the storage of vectors and facilitates the retrieval of related vectors.
  - 6): Utilize a query function to coordinate query encoding and execute a k-NN search.

- The reference code can be accessed at this location [here](https://github.com/mingyu110/Best-Practice/blob/main/Data%26AI/CLIP%20with%20Opensearch.ipynb)
